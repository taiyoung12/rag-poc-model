import streamlit as st
import requests
import time
from streamlit_autorefresh import st_autorefresh

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="LLM Response Viewer", page_icon="ğŸ¤–", layout="centered")

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ’¬ LLM Response Viewer")
st.write("ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")

# ì‚¬ì´ë“œë°”ì— ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€
st.sidebar.title("ğŸ”§ ì„¤ì •")
st.sidebar.write("ì´ í˜ì´ì§€ë¥¼ í†µí•´ LLMê³¼ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. API ì„œë²„ê°€ ì‘ë™ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")

# ì‚¬ìš©ì ì…ë ¥ ì„¹ì…˜
st.header("ğŸ” Send a Message")

# ì‚¬ìš©ì ì…ë ¥ í¼
with st.form("message_form"):
    keyword = st.selectbox(
        "Choose a keyword:",
        options=["ë§ˆì´ë°ì´í„°", "ë§ˆì´ë°ì´í„°_API"],
        help="ë©”ì‹œì§€ë¥¼ ìœ„í•œ í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”."
    )
    
    prompt = st.text_input("Enter your prompt:", help="LLMì— ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # í¼ ì œì¶œ ë²„íŠ¼
    submitted = st.form_submit_button("Send")

    if submitted:
        if keyword and prompt:
            # APIì— ìš”ì²­ ë³´ë‚´ê¸°
            try:
                url = f"http://localhost:8080/rag?keyword={keyword}&prompt={prompt}"
                response = requests.get(url)
                response.raise_for_status()
                st.success("âœ… ë©”ì‹œì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.json(response.json())  # API ì‘ë‹µì„ JSON í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
            except requests.exceptions.RequestException as e:
                st.error(f"âŒ ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        else:
            st.warning("âš ï¸ ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")

# ì‹¤ì‹œê°„ ì‘ë‹µ ì„¹ì…˜
st.header("ğŸ“¨ Latest LLM Response")

# ì„œë²„ë¡œë¶€í„° ìµœì‹  ì‘ë‹µ ê°€ì ¸ì˜¤ê¸° (ì£¼ê¸°ì  ì—…ë°ì´íŠ¸)
response_container = st.empty()

# ì£¼ê¸°ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê°„ë‹¨í•œ ë°©ë²•: st_autorefreshë¥¼ ì‚¬ìš©í•´ ì£¼ê¸°ì ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨
count = st_autorefresh(interval=5000, limit=100, key="refresh")

# ì„œë²„ì—ì„œ ìµœì‹  ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
def fetch_latest_response():
    try:
        response = requests.get("http://localhost:8080/llm-response")
        response.raise_for_status()
        return response.text
    except requests.exceptions.RequestException as e:
        return f"âŒ ìµœì‹  ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# ì£¼ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” LLM ì‘ë‹µ í‘œì‹œ
latest_response = fetch_latest_response()
response_container.write(latest_response)